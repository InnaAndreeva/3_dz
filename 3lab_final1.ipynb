{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "3lab_final1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InnaAndreeva/3_dz/blob/master/3lab_final1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAD0i1wc9WJ9",
        "colab_type": "code",
        "outputId": "c0c90a55-f902-4bc3-e967-bb3466541a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.python.keras.datasets import cifar10  \n",
        "import numpy as np \n",
        "import time\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.python import debug as tf_debug"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9TgBrzW9WKD",
        "colab_type": "code",
        "outputId": "b58c3a2b-8497-4dd2-e30f-3348b00ca3af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt3cRWaC9WKI",
        "colab_type": "code",
        "outputId": "33764266-10a1-4d2a-d08b-72351527c9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "nb_classes = 10\n",
        "print(y_train.shape)\n",
        "y_train = y_train.reshape(y_train.shape[0])  # somehow y_train comes as a 2D nx1 matrix\n",
        "y_test = y_test.reshape(y_test.shape[0])\n",
        "x_train = X_train.astype('float32')\n",
        "x_test = X_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "x_train = np.reshape(x_train, [-1, 3072])\n",
        "x_test  = np.reshape(x_test, [-1, 3072])\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v36xAtS9WKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable(shape): # создание переменной весов слоя\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1) \n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape): \n",
        "    initial = tf.constant(0.1, shape=shape) \n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def conv2d(x_, W):  # операция свертки\n",
        "    return tf.nn.conv2d(x_, W, strides=[1, 1, 1, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ459Dml9WKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pool_2x2(x_): # операция пулинга \n",
        "    return tf.nn.max_pool(x_, ksize=[1, 2, 2, 1], \n",
        "                          strides=[1, 2, 2, 1], padding='SAME')\n",
        "def conv_layer(input, shape): # сверточный слой\n",
        "    W = weight_variable(shape) # переменная для весов свертки\n",
        "    b = bias_variable([shape[3]]) # свободные члены = количество фильтров\n",
        "    return tf.nn.relu(conv2d(input, W) + b)\n",
        "def full_layer(input, size): \n",
        "    in_size = int(input.get_shape()[1]) \n",
        "    W = weight_variable([in_size, size]) \n",
        "    b = bias_variable([size]) \n",
        "    return tf.matmul(input, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtI6b-r79WKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3072])  # создаем переменную для x\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10]) \n",
        "keep_prob = tf.placeholder(tf.float32)  # переменная для dropout\n",
        "x_image = tf.reshape(x, [-1, 32, 32, 3])  # преобразование в размеры картинки"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teDJKQcM9WKc",
        "colab_type": "code",
        "outputId": "595fa949-0cb6-4bbc-fbe0-a36c2b923e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "with tf.name_scope('conv_1'): \n",
        "    conv1 = conv_layer(x_image, shape=[3, 3, 3, 32]) # создание сверточного слоя    \n",
        "    conv1_pool = max_pool_2x2(conv1) # слой пулинга\n",
        "with tf.name_scope('conv_2'): \n",
        "    conv2 = conv_layer(conv1_pool, shape=[3, 3, 32, 64]) \n",
        "    conv2_pool = max_pool_2x2(conv2) \n",
        "with tf.name_scope('conv_3'): \n",
        "#     conv3 = conv_layer(conv2, shape=[3, 3, 64, 128]) \n",
        "    conv3 = conv_layer(conv2_pool, shape=[3, 3, 64, 128]) \n",
        "    conv3_pool = max_pool_2x2(conv3) \n",
        "    conv3_flat = tf.reshape(conv3_pool, [-1, 4*4*128]) \n",
        "with tf.name_scope('full_1'): \n",
        "    full_1 = tf.nn.relu(full_layer(conv3_flat, 512)) \n",
        "with tf.name_scope('dropout'): \n",
        "    full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob) \n",
        "with tf.name_scope('activations'): \n",
        "    y_conv = full_layer(full1_drop, 10) \n",
        "    tf.summary.scalar('cross_entropy_loss',y_conv)\n",
        "with tf.name_scope('cross'): \n",
        "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv, labels=y_)) \n",
        "# #SGD \n",
        "train_step = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1)) \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-c886dd68c907>:15: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DzmvFMq9WKh",
        "colab_type": "code",
        "outputId": "2110de30-53f2-4412-80d1-93682ea008a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer()) \n",
        "    start_time = time.time()\n",
        "    for epochs in range(5):\n",
        "        for i in range(2500):  \n",
        "            batch = [x_train[20*i:20*(i+1)] , y_train[20*i:20*(i+1)]]\n",
        "\n",
        "            if i % 250 == 0:       \n",
        "                train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], \n",
        "                                                               y_: batch[1], keep_prob: 1.0}) \n",
        "                print(\"time {}, step {}, training accuracy {}\".format(time.time() - start_time,i, train_accuracy)) \n",
        "            sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "        print('-----------------------------------------------Эпоха№', epochs)\n",
        "        X = x_test.reshape(10, 1000, 3072) \n",
        "        Y = y_test.reshape(10, 1000, 10) \n",
        "        test_accuracy = np.mean([sess.run(accuracy, feed_dict={x:X[i], y_:Y[i], keep_prob:1.0}) for i in range(10)])\n",
        "        print(\"test accuracy: {}\".format(test_accuracy))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time 0.1654977798461914, step 0, training accuracy 0.10000000149011612\n",
            "time 12.334223985671997, step 250, training accuracy 0.20000000298023224\n",
            "time 24.44785714149475, step 500, training accuracy 0.550000011920929\n",
            "time 36.69976234436035, step 750, training accuracy 0.44999998807907104\n",
            "time 48.92852592468262, step 1000, training accuracy 0.44999998807907104\n",
            "time 61.22667956352234, step 1250, training accuracy 0.5\n",
            "time 73.58510637283325, step 1500, training accuracy 0.5\n",
            "time 85.92834329605103, step 1750, training accuracy 0.6000000238418579\n",
            "time 98.25592517852783, step 2000, training accuracy 0.44999998807907104\n",
            "time 110.75135207176208, step 2250, training accuracy 0.800000011920929\n",
            "-----------------------------------------------Эпоха№ 0\n",
            "test accuracy: 0.5436999201774597\n",
            "time 129.17269706726074, step 0, training accuracy 0.6499999761581421\n",
            "time 141.76247787475586, step 250, training accuracy 0.550000011920929\n",
            "time 154.28582215309143, step 500, training accuracy 0.75\n",
            "time 166.81885862350464, step 750, training accuracy 0.800000011920929\n",
            "time 179.3621530532837, step 1000, training accuracy 0.5\n",
            "time 191.60081672668457, step 1250, training accuracy 0.6000000238418579\n",
            "time 203.80499410629272, step 1500, training accuracy 0.550000011920929\n",
            "time 215.9753270149231, step 1750, training accuracy 0.699999988079071\n",
            "time 228.1873517036438, step 2000, training accuracy 0.6499999761581421\n",
            "time 240.3783619403839, step 2250, training accuracy 1.0\n",
            "-----------------------------------------------Эпоха№ 1\n",
            "test accuracy: 0.6405999660491943\n",
            "time 258.3870520591736, step 0, training accuracy 0.75\n",
            "time 270.5970242023468, step 250, training accuracy 0.699999988079071\n",
            "time 283.0937442779541, step 500, training accuracy 0.800000011920929\n",
            "time 295.60991191864014, step 750, training accuracy 0.8500000238418579\n",
            "time 308.12752747535706, step 1000, training accuracy 0.5\n",
            "time 320.69721484184265, step 1250, training accuracy 0.6499999761581421\n",
            "time 333.24648690223694, step 1500, training accuracy 0.550000011920929\n",
            "time 345.9929370880127, step 1750, training accuracy 0.800000011920929\n",
            "time 358.645546913147, step 2000, training accuracy 0.6499999761581421\n",
            "time 371.19546341896057, step 2250, training accuracy 1.0\n",
            "-----------------------------------------------Эпоха№ 2\n",
            "test accuracy: 0.6778000593185425\n",
            "time 389.7210941314697, step 0, training accuracy 0.8500000238418579\n",
            "time 402.2245876789093, step 250, training accuracy 0.699999988079071\n",
            "time 414.8516037464142, step 500, training accuracy 0.8999999761581421\n",
            "time 427.6398138999939, step 750, training accuracy 0.8999999761581421\n",
            "time 440.33345556259155, step 1000, training accuracy 0.75\n",
            "time 452.9991338253021, step 1250, training accuracy 0.699999988079071\n",
            "time 465.71265029907227, step 1500, training accuracy 0.699999988079071\n",
            "time 478.32589745521545, step 1750, training accuracy 0.800000011920929\n",
            "time 490.9629192352295, step 2000, training accuracy 0.800000011920929\n",
            "time 503.61352586746216, step 2250, training accuracy 0.949999988079071\n",
            "-----------------------------------------------Эпоха№ 3\n",
            "test accuracy: 0.7019000053405762\n",
            "time 522.1358065605164, step 0, training accuracy 0.949999988079071\n",
            "time 534.7370636463165, step 250, training accuracy 0.75\n",
            "time 547.2885420322418, step 500, training accuracy 0.949999988079071\n",
            "time 559.7174110412598, step 750, training accuracy 1.0\n",
            "time 571.9606516361237, step 1000, training accuracy 0.800000011920929\n",
            "time 584.306886434555, step 1250, training accuracy 0.699999988079071\n",
            "time 596.6232817173004, step 1500, training accuracy 0.699999988079071\n",
            "time 608.9854702949524, step 1750, training accuracy 0.8500000238418579\n",
            "time 621.2842898368835, step 2000, training accuracy 0.800000011920929\n",
            "time 633.5914151668549, step 2250, training accuracy 1.0\n",
            "-----------------------------------------------Эпоха№ 4\n",
            "test accuracy: 0.7211999893188477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS19z3m19WKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6LGDet_9WKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}